# High-Resolution Image Synthesis with Latent Diffusion Models

使用潛在擴散模型的高分辨率圖像合成

> https://arxiv.org/pdf/2112.10752.pdf



## Abstract

通過將圖像形成過程分解為去噪自動編碼器的順序應用，擴散模型 (DM) 在圖像數據及其他方面實現了最先進的合成結果。



為了在有限的計算上啟用 DM 訓練,在保留資源的質量和靈活性的同時，我們將它們應用到強大的預訓練自動編碼器的潛在空間中。



## Introduction

### Image Synthesis的歷史發展

圖像合成是最近發展最引人注目的計算機視覺領域之一，也是計算需求最大的領域之一。 特別是複雜自然場景的高分辨率合成目前主要是基於擴展可能性的模型，自回歸（AR）變壓器中可能包含數十億個參數



相比之下，GAN 的有希望的結果主要局限於可變性相對有限的數據，因為它們的對抗性學習過程不容易擴展到建模複雜的多模態分佈。



最近，由[去噪自動編碼器](https://arxiv.org/pdf/1503.03585.pdf)層次結構構建的擴散模型 [82] 已證明在圖像合成方面取得了令人印象深刻的結果



此外，與其他類型的生成模型相比，即使是**無條件 DM(Diffusion models )** 也可以輕鬆應用於修復和著色 或基於筆劃的合成  等任務



作為基於可能性的模型，它們不會像GAN 那樣表現出模式崩潰和訓練不穩定性，並且通過大量利用參數共享，它們可以對自然圖像的高度複雜分佈進行建模，而無需像AR 模型那樣涉及數十億個參數



**Democratizing High-Resolution Image Synthesis DMs**

大眾化高分辨率圖像合成 DM 屬於基於可能性的模型類別，其模式覆蓋行為使它們容易花費過多的容量（以及計算資源），對數據的難以察覺的細節進行建模



儘管重新加權的變分目標[30]旨在通過對初始去噪步驟進行欠採樣來解決這個問題，但DM的計算要求仍然很高，因為訓練和評估這樣的模型需要在RGB圖像的高維空間中重複進行函數評估（和梯度計算） 。

### 解決方法

為了減少對算力的需求，在不影響 DM 性能的情況下減少 DM 的計算需求是增強其可訪問性的關鍵



**Departure to Latent Space** 首先的嘗試是分析在像素空間上的已訓練的diffusion models 擴散模型



<img src= 'paper_imgs/High-Resolution Image Synthesis with Latent Diffusion Models-fig2.png'>

顯示了訓練有素的率失真權衡模型。 與任何基於可能性的模型一樣，學習可以大致分為兩個階段：<u>**第一個階段**是感知壓縮階段，刪除高頻細節但仍然學到很少的語義變化</u>。 **在第二階段**<u>，實際的生成模型學習數據的語義和概念組成（語義壓縮）</u>。 因此，我們的目標是首先找到一個感知上等效但計算上更合適的空間，在其中我們將訓練用於高分辨率圖像合成的擴散模型。





我們把訓練分割成，兩個獨立的階段。

首先，我們訓練一個自編碼器，用來提供低維度的表徵空間，在感知上於數據空間等效。更重要的是，與之前不同的是，<u>我們不需要依賴過度的空間壓縮，因為我們在學習到的潛在空間中訓練 DM，這在空間維度方面表現出更好的縮放特性。</u> 降低的複雜性還提供了從潛在圖像生成的高效圖像
具有單一網絡通行證的空間。 我們將生成的模型類稱為“潛在擴散模型”(LDM)。



這種方法的一個顯著優點是我們只需要訓練通用自動編碼階段一次，因此可以將其重複用於多個 DM 訓練或探索可能完全不同的任務。



對於後者，我們設計了一個架構，將 Transformer 連接到 DM 的 UNet 主幹 [71]，並啟用任意類型的基於令牌的調節機制，



## Related Work

**Generative Models for Image Synthesis**

GAN 產生圖片很有效去獲取特徵，但又不是全部特徵，同時很難去優化， 

相比之下，基於似然的方法強調良好的密度估計，這使得優化表現得更好。



最近，**Diffusion Probabilistic Models（DM）**

在密度估計以及樣本質量方面取得了最先進的結果。



當這些模型的底層神經主幹被實現為 UNet 時，這些模型的生成能力源於對類圖像數據的歸納偏差的自然擬合，當使用重新加權的目標[30]進行訓練時，通常可以實現最佳的綜合質量。 在這種情況下，DM 相當於有損壓縮器，並允許以圖像質量換取壓縮能力



**Two-Stage Image Synthesis** 

為了減輕個體生成方法的缺點，大量研究已經通過兩階段方法將不同方法的優點結合成更高效和性能更高的模型。 VQ-VAE  使用自回歸模型來學習離散潛在空間的表達先驗。





## Method

我們觀察到，儘管擴散模型允許通過對相應的損失項進行欠採樣來忽略感知上不相關的細節[30]，但它們仍然需要在像素空間中進行昂貴的函數評估，這對計算時間和能源資源造成巨大的需求。



我們建議通過引入**壓縮學習階段和生成學習階段**的明確分離來規避這個缺點（見圖 2）。 為了實現這一目標，我們利用自動編碼模型，該模型學習感知上與圖像空間等效的空間，但顯著降低了計算複雜度





### Perceptual Image Compression

感知圖像壓縮

我們的感知壓縮模型基於之前的工作[23]，由一個通過感知損失[106]和基於補丁的[33]對抗目標相結合訓練的自動編碼器組成



這確保了通過強制局部真實性將重建限制在圖像流形內，並避免僅依賴像素空間損失（例如 L2 或 L1 目標）而引入的模糊。



### Latent Diffusion Models

擴散模型是概率模型，旨在通過逐漸對正態分佈變量進行去噪來學習數據分佈p(x)，這對應於學習長度為T的固定馬爾可夫鏈的逆過程。



### Conditioning Mechanisms



## Limitations & Societal Impact

局限性和社會影響

**Limitations**雖然與基於像素的方法相比，LDM 顯著降低了計算要求，但它們的順序採樣過程仍然比 GAN 慢。 此外，當需要高精度時，LDM 的使用可能會受到質疑：儘管在我們的f = 4 自動編碼模型中圖像質量的損失非常小（見圖1），但它們的重建能力可能成為需要精細精度的任務的瓶頸。 - 像素空間的粒度精度。 我們假設我們的超分辨率模型
（第 4.4 節）在這方面已經受到一定限制。

**Societsl Impact**

圖像等媒體的生成模型是一把雙刃劍



